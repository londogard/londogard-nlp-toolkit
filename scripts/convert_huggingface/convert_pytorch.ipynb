{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (4.21.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (2022.8.17)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp310-cp310-win_amd64.whl (162.2 MB)\n",
      "     -------------------------------------- 162.2/162.2 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hampu\\documents\\dev\\koitz-stack\\venv\\lib\\site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"Alireza1044/albert-base-v2-sst2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, torchscript=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  2,  31, 101,  42,  15,  31, 339,  42,   3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_out = tokenizer(\"I like you, I love you\", return_tensors=\"pt\"); tok_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[  2,  31, 101,  42,  15,  31, 339,  42,   3]]),\n tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok_out['input_ids'], tok_out['attention_mask']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Model saved at 'traced_Alireza1044/albert-base-v2-sst2.pt'\""
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, [tok_out['input_ids'], tok_out['attention_mask']])\n",
    "Path(f\"traced_{model_name}\").parent.mkdir(exist_ok=True)\n",
    "torch.jit.save(traced_model, f\"traced_{model_name}.pt\")\n",
    "\n",
    "f\"Model saved at 'traced_{model_name}.pt'\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}