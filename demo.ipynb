{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forbidden-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "@file:Repository(\"https://jitpack.io\")\n",
    "@file:DependsOn(\"com.londogard:londogard-nlp-toolkit:local-SNAPSHOT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-assistant",
   "metadata": {},
   "source": [
    "# Londogard NLP Toolkit\n",
    "This is a simple toolkit for Natural Language Processing (NLP) which will contain utilities that are very handy while prototyping.  \n",
    "The initial aim is not to solve problems end-2-end but rather have a simple small dependency with great utilities.\n",
    "\n",
    "## Supported Utilities\n",
    "\n",
    "All completed utilities with simple usage accompanied. `LanguageSupport.<ISO_2_COUNTRY_CODE>` helps figuring out what is supported.\n",
    "\n",
    "- [Word Embeddings](#WordEmbeddings) including basic Word Embeddings, 'Light Word Embeddings' & BytePairEmbeddings\n",
    "    - See supported languages in the chapter (BPE-Embeddings support 275 languages!).\n",
    "- [Sentence Embeddings](#SentenceEmbeddings) including `AvgSentenceEmbeddings` & `USifEmbeddings`\n",
    "    - See supported languages in the chapter.\n",
    "- [Tokenizers](#Tokenizers) including Word, Char & Subword (SentencePiece) tokenizers (simple to add custom logic)\n",
    "- [Stopwords](#Stopwords) based on NLTKs list\n",
    "    - Supporting: ar, az, da, de, el, en, es, fi, fr, hu, id, it, kk, ne, nl, no, pt, ro, ru, sl, sv, tg & tr\n",
    "- [Word Frequencies](#WordFrequencies) based on `wordfreq.py` by [LuminosoInsight](https://github.com/LuminosoInsight/wordfreq/).\n",
    "    - Supporting: ar, cs, de, en, es, fi, fr, it, ja, nl, pl, uk, pt, ru, zh, bg, bn, ca, da, el, fa, he, hi, hu, id, ko, lv, mk, ms, nb, ro, sh, sv & tr. Some of these support \"Large Word Frequency\", call `LanguageSupport.<LANG_CODE>.largestWordFrequency()` to see if `large` variant is available.\n",
    "- [Stemmer](#Stemmer) based on [Snowball Stemmer](https://snowballstem.org/)\n",
    "    - Supporting: sv, nl, en, fi, fr, de, hu, it, no, pt, ro, ru, es & tr\n",
    "- [Trie](#Trie) - Just a basic utility that is to be used for a custom SubwordTokenizer in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-timeline",
   "metadata": {},
   "source": [
    "### WordEmbeddings\n",
    "Word Embeddings currently exists in three variants. \n",
    "\n",
    "All Embeddings (excluding SentenceEmbeddings) extend `Embeddings` which have some good-to-know default methods:\n",
    "```kotlin\n",
    "interface Embeddings {\n",
    "    fun contains(word: String): Boolean\n",
    "    \n",
    "    fun vector(word: String): SimpleMatrix?\n",
    "    \n",
    "    // OBS: Will return all possible vectors, not necessarily ALL\n",
    "    fun traverseVectors(words: List<String>): List<SimpleMatrix>\n",
    "    fun traverseVectorsOrNull(words: List<String>): List<SimpleMatrix>? // Returns null if any missing\n",
    "    \n",
    "    fun euclideanDistance(w1: String, w2: String): Double?\n",
    "    fun cosineDistance(w1: String, w2: String): Double?\n",
    "}\n",
    "```\n",
    "\n",
    "#### WordEmbedding\n",
    "\n",
    "`WordEmbeddings` are the classical usecase of Embeddings where each word maps to a vector of floats. There exists some helper-methods. Currently requires to have the embeddings locally. \n",
    "Download functions for [fastText](https://fasttext.cc/) will come, but be warned they're large!\n",
    "\n",
    "```kotlin\n",
    "class WordEmbeddings(val delimeter: Char = ' ', val dimensions: Int, val filePath: Path) {\n",
    "    // Returns the N nearest neighbours\n",
    "    fun nearestNeighbour(vector: SimpleMatrix, N: Int): List<Pair<String, Double>>\n",
    "    \n",
    "    // Returns N nearest neighbours, for the average of all input\n",
    "    fun distance(input: List<String>, N: Int): List<Pair<String, Double>>\n",
    "    \n",
    "    // w1 is to w2 what w3 is to ??. The N closest choices to ?? is selected\n",
    "    fun analogy(w1: String, w2: String, w3: String, N: Int): List<Pair<String, Double>>?\n",
    "    \n",
    "    // Rank a set of words by their distance to word\n",
    "    fun rank(word: String, set: Set<String>): List<Pair<String, Double>>\n",
    "    \n",
    "    // Pretty print the returned wordlist\n",
    "    fun pprint(words: List<Pair<String, Double>>)\n",
    "}\n",
    "```\n",
    "\n",
    "#### LightWordEmbedding\n",
    "\n",
    "`LightWordEmbeddings` is something we at Londogard created to allow our embeddings to be loaded onto a Raspberry Pi 3B+ (1GB RAM). What's so effective about the `LightWordEmbeddings` is that ~ 10 % of all words makes up 90 % of all communications meaning that by just having a few embeddings (the most common ones) we cover most cases and can load the rest when required.  \n",
    "They don't come free as you can't call the unique functions from `WordEmbeddings` such as `nearestNeighbour` and are a little bit more complicated to use.\n",
    "\n",
    "```kotlin\n",
    "class LightWordEmbeddings(val delimeter: Char = ' ', val dimensions: Int, val filePath: Path, val maxWordCount: Int = 1000) {\n",
    "    \n",
    "    // add words you'd like to read into the embeddings.\n",
    "    // only delta from already loaded words are added, e.g. if everything is loaded it won't head to filesystem\n",
    "    // the `maxWordCount` most common words are preloaded as part of instatiation\n",
    "    fun addWords(words: Set<String) \n",
    "}\n",
    "```\n",
    "\n",
    "#### BytePieceEncoding-Embedding (BPEmb)\n",
    "BytePieceEncoding-Embeddings are a new approach from _BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages_ by Benjamin Heinzerling and Michael Strube. In this paper they show how a 11 MB embedding for English is on par with 6 GB embeddings from `fastText`!\n",
    "\n",
    "The default behaviour is that the tokenizer tokenize a word and average the embedding. It's also possible to use the extended method `subwordVector` to directly retrieve the embedding if you pretokenized the text. Remember if using `subwordVector` it's important that you choose the same vocab-size, otherwise you'll see a lot of misses!\n",
    "\n",
    "```kotlin\n",
    "class BpeEmbeddings {\n",
    "    fun subwordVector(subword: String): SimpleMatrix?\n",
    "}\n",
    "```\n",
    "\n",
    "#### EmbeddingLoader\n",
    "Finally there exists a utility function that helps you load & download embeddings automatically and saving them on filesystem. \n",
    "\n",
    "Let's see how we can use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innovative-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java.lang.IllegalStateException: This sequence can be consumed only once.\n",
      "kotlin.sequences.ConstrainedOnceSequence.iterator(SequencesJVM.kt:23)\n",
      "kotlin.sequences.TransformingSequence$iterator$1.<init>(Sequences.kt:208)\n",
      "kotlin.sequences.TransformingSequence.iterator(Sequences.kt:207)\n",
      "kotlin.sequences.FilteringSequence$iterator$1.<init>(Sequences.kt:164)\n",
      "kotlin.sequences.FilteringSequence.iterator(Sequences.kt:163)\n",
      "kotlin.sequences.TakeSequence$iterator$1.<init>(Sequences.kt:411)\n",
      "kotlin.sequences.TakeSequence.iterator(Sequences.kt:409)\n",
      "kotlin.sequences.SequencesKt___SequencesKt.toCollection(_Sequences.kt:752)\n",
      "kotlin.sequences.SequencesKt___SequencesKt.toMutableList(_Sequences.kt:782)\n",
      "kotlin.sequences.SequencesKt___SequencesKt.toList(_Sequences.kt:773)\n",
      "com.londogard.nlp.embeddings.EmbeddingLoader.fromFile$nlp(EmbeddingLoader.kt:39)\n",
      "com.londogard.nlp.embeddings.LightWordEmbeddings.loadEmbeddings(LightWordEmbeddings.kt:33)\n",
      "com.londogard.nlp.embeddings.LightWordEmbeddings.<init>(LightWordEmbeddings.kt:16)\n",
      "com.londogard.nlp.embeddings.LightWordEmbeddings.<init>(LightWordEmbeddings.kt:11)\n",
      "Line_15_jupyter.<init>(Line_15.jupyter.kts:23)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\n",
      "kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.evalWithConfigAndOtherScriptsResults(BasicJvmScriptEvaluator.kt:96)\n",
      "kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.invoke$suspendImpl(BasicJvmScriptEvaluator.kt:41)\n",
      "kotlin.script.experimental.jvm.BasicJvmScriptEvaluator.invoke(BasicJvmScriptEvaluator.kt)\n",
      "kotlin.script.experimental.jvm.BasicJvmReplEvaluator.eval(BasicJvmReplEvaluator.kt:51)\n",
      "org.jetbrains.kotlin.jupyter.ReplForJupyterImpl$doEval$resultWithDiagnostics$1.invokeSuspend(repl.kt:604)\n",
      "kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n",
      "kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:56)\n",
      "kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:274)\n",
      "kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:84)\n",
      "kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:59)\n",
      "kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)\n",
      "kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:38)\n",
      "kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)\n",
      "org.jetbrains.kotlin.jupyter.ReplForJupyterImpl.doEval(repl.kt:604)\n",
      "org.jetbrains.kotlin.jupyter.ReplForJupyterImpl.eval(repl.kt:434)\n",
      "org.jetbrains.kotlin.jupyter.ProtocolKt$shellMessagesHandler$res$1.invoke(protocol.kt:248)\n",
      "org.jetbrains.kotlin.jupyter.ProtocolKt$shellMessagesHandler$res$1.invoke(protocol.kt)\n",
      "org.jetbrains.kotlin.jupyter.ProtocolKt.evalWithIO(protocol.kt:400)\n",
      "org.jetbrains.kotlin.jupyter.ProtocolKt.shellMessagesHandler(protocol.kt:247)\n",
      "org.jetbrains.kotlin.jupyter.IkotlinKt.kernelServer(ikotlin.kt:127)\n",
      "org.jetbrains.kotlin.jupyter.IkotlinKt.kernelServer$default(ikotlin.kt:95)\n",
      "org.jetbrains.kotlin.jupyter.IkotlinKt.main(ikotlin.kt:72)\n"
     ]
    }
   ],
   "source": [
    "import com.londogard.nlp.embeddings.*\n",
    "import com.londogard.nlp.utils.LanguageSupport.*\n",
    "\n",
    "EmbeddingLoader.fromLanguageOrNull<WordEmbeddings>(sv) // WordEmbeddings\n",
    "// EmbeddingLoader.fromLanguageOrNull<BpeEmbeddings>(sv) // BpeEmbeddings (vocabSize: 10_000, dim: 50)\n",
    "EmbeddingLoader.fromLanguageOrNull<LightWordEmbeddings>(sv) // LightWordEmbeddings (size: 1000)\n",
    "\n",
    "val embeddings = EmbeddingLoader.fromLanguageOrNull<WordEmbeddings>(sv)\n",
    "\n",
    "embeddings?.vector(\"hej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-crash",
   "metadata": {},
   "source": [
    "### SentenceEmbeddings\n",
    "\n",
    "All Sentence Embeddings extend the same `interface`\n",
    "```kotlin\n",
    "interface SentenceEmbeddings {\n",
    "    val tokenEmbeddings: Embeddings\n",
    "    fun getSentenceEmbeddings(listOfSentences: List<List<String>>): List<SimpleMatrix>\n",
    "    fun getSentenceEmbedding(sentence: List<String>): SimpleMatrix\n",
    "}\n",
    "```\n",
    "\n",
    "The `fun getSentenceEmbeddings(listOfSentences: List<List<String>>)` exists because some Sentence Embeddings depends on the \"global context\".\n",
    "\n",
    "Currently two variants are 'completed' but more are coming.\n",
    "\n",
    "#### AvgSentenceEmbeddings\n",
    "Just averages the Word Embeddings for a sentence.\n",
    "\n",
    "#### USifSentenceEmbeddings\n",
    "This implementation is based on the paper _Unsupervised Random Walk Sentence Embeddings: A Strong but Simple Baseline_ by Kawin Ethayarajh, found on [aclweb.org](https://www.aclweb.org/anthology/W18-3012/).  \n",
    "This paper bases its work on Smooth-Inverse-Frequency (SIF) Embeddings (paper _A Simple but Tough-to-Beat Baseline for Sentence Embeddings_ found [here](https://openreview.net/forum?id=SyK00v5xx)). The difference being that this approach is _unsupervised_ while remaining even stronger. See the abstract:\n",
    "\n",
    "> Using a random walk model of text generation, Arora et al. (2017) proposed a strong baseline for computing sentence embeddings: take a weighted average of word embeddings and modify with SVD. This simple method even outperforms far more complex approaches such as LSTMs on textual similarity tasks. In this paper, we first show that word vector length has a confounding effect on the probability of a sentence being generated in Arora et al.’s model. We propose a random walk model that is robust to this confound, where the probability of word generation is inversely related to the angular distance between the word and sentence embeddings. Our approach beats Arora et al.’s by up to 44.4% on textual similarity tasks and is competitive with state-of-the-art methods. Unlike Arora et al.’s method, ours requires no hyperparameter tuning, which means it can be used when there is no labelled data.\n",
    "\n",
    "What has to be noted is that it requires more input than other `SentenceEmbeddings` see\n",
    "\n",
    "```kotlin\n",
    "import com.londogard.nlp.embeddings.sentence.*\n",
    "\n",
    "class USifSentenceEmbeddings(\n",
    "    val tokenEmbeddings: Embeddings,\n",
    "    private val wordProb: Map<String, Float>,\n",
    "    randomWalkLength: Int, // = n, ~11\n",
    "    val numCommonDiscourseVector: Int = 5 // = m, 0 should work. In practise max 5.\n",
    ") {\n",
    "    /** use it the same way as SentenceEmbeddings */\n",
    "}\n",
    "```\n",
    "\n",
    "Where `wordProb` is simply taken through the `WordFrequencies` util. E.g. `WordFrequencies.getAllWordFrequenciesOrNull(sv): Map<String, Float>?`.\n",
    "\n",
    "#### SentenceEmbeddings In Progress\n",
    "\n",
    "`TfIdfEmbeddings` & `SifEmbeddings`, the latter might be scrapped as `USif` is such a amazing work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-short",
   "metadata": {},
   "source": [
    "### Tokenizers\n",
    "\n",
    "There currently exists three types of tokenizers all extending the same `interface`.\n",
    "\n",
    "```kotlin\n",
    "interface Tokenizer {\n",
    "    fun split(text: String): List<String>\n",
    "}\n",
    "```\n",
    "\n",
    "#### CharTokenizer\n",
    "\n",
    "Tokenizes a string into the chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.londogard.nlp.tokenizer.*\n",
    "\n",
    "CharTokenizer().split(\"hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-russia",
   "metadata": {},
   "source": [
    "#### SimpleTokenizer\n",
    "\n",
    "This is a word-tokenizer which splits out words based on a few different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleTokenizer().split(\"hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-queen",
   "metadata": {},
   "source": [
    "#### SentencePieceTokenizer\n",
    "The SentencePiece Tokenizer is a subword tokenizer which is Language Specific, through [BPEmb](https://nlp.h-its.org/bpemb/) we have 275 languages covered through Wikipedia. There exists model of the following vocab-sizes: `1000, 3000, 5000, 10_000, 25_000, 50_000, 100_000 & 200_000`. The larger vocab the less subwords are tokenized and more words.\n",
    "\n",
    "The SentencePiece model is the raw C++ from [Google](https://github.com/google/sentencepiece/) with a wrapper from [DJL (Amazon)](http://docs.djl.ai/extensions/sentencepiece/index.html). I'm usually very hesitant in adding native libraries (JNI) when working on JVM-projects but no-one can deny the power of SentencePiece and I haven't had the time to implement the algorithm myself.  \n",
    "This wrapper by DJL is very small (they provide a single dependency with only sentencepiece) and fits my philosophy of keeping dependencies and size at a low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-ferry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "purple-yugoslavia",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "The stopwords are taken from NLTK and are hosted directly on the GitHub. The object looks as follows:\n",
    "\n",
    "```kotlin\n",
    "object Stopwords {\n",
    "    fun isStopword(word: String, language: LanguageSupport): Boolean\n",
    "    fun stopwords(language: LanguageSupport): Set<String> // Throws if language does not support stopwords\n",
    "    fun stopwordsOrNull(language: LanguageSupport): Set<String>?\n",
    "}\n",
    "```\n",
    "\n",
    "This object has an internal cache which saves the previously loaded language. Use `Stopwords.stopwords` to simply retrieve the Stopwords and use them yourself as a `Set<String>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.londogard.nlp.stopwords.Stopwords\n",
    "import com.londogard.nlp.utils.LanguageSupport.*\n",
    "\n",
    "val hej = Stopwords.isStopword(\"hej\", sv)\n",
    "val och = Stopwords.isStopword(\"och\", sv)\n",
    "\n",
    "\"'hej' is a stopword: $hej\\n'och' is a stopword: $och\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords.stopwords(sv).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "runCatching { Stopwords.stopwords(af) }.isSuccess // Stopwords does not support af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords.stopwordsOrNull(af) == null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-adaptation",
   "metadata": {},
   "source": [
    "### WordFrequencies\n",
    "\n",
    "The Word Frequencies are taken from `wordfreq.py` a library by [LuminosoInsight](https://github.com/LuminosoInsight/wordfreq/) and are hosted directly on the GitHub. The object looks as follows:\n",
    "\n",
    "```kotlin\n",
    "object WordFrequencies {\n",
    "   fun getAllWordFrequenciesOrNull(language: LanguageSupport, size: WordFrequencySize = WordFrequencySize.Largest): Map<String, Float>?\n",
    "   \n",
    "   fun wordFrequency(word: String, language: LanguageSupport, minimum: Float = 0f, size: WordFrequencySize): Float // Throws if language does not support wordfreq\n",
    "   fun wordFrequencyOrNull( word: String, language: LanguageSupport, minimum: Float = 0f, size: WordFrequencySize): Float?\n",
    "}\n",
    "```\n",
    "\n",
    "This object has an internal cache which saves the previously loaded language. Use `WordFrequencies.getAllWordFrequenciesOrNull` to simply retrieve the WordFrequencies and use them yourself as a `Map<String, Float>`.  \n",
    "Methods to recieve `zipfFrequencies` also exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.londogard.nlp.wordfreq.WordFrequencies\n",
    "\n",
    "val hej = WordFrequencies.wordFrequency(\"hej\", sv)\n",
    "val och = WordFrequencies.wordFrequency(\"och\", sv)\n",
    "\n",
    "\"WordFrequency of 'hej'=$hej and 'och'=$och\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "val hej = WordFrequencies.zipfFrequency(\"hej\", sv)\n",
    "val och = WordFrequencies.zipfFrequency(\"och\", sv)\n",
    "\n",
    "\"ZipfFrequency of 'hej'=$hej and 'och'=$och\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "val weird = WordFrequencies.wordFrequency(\"hraihaodjasmdiamo\", sv)\n",
    "val weirdOrNull = WordFrequencies.wordFrequencyOrNull(\"hraihaodjasmdiamo\", sv)\n",
    "\n",
    "\"WordFrequency of 'hraihaodjasmdiamo' (non-word) using `wordFrequency` $weird and using `wordFrequencyOrNull` $weirdOrNull\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "runCatching { WordFrequencies.wordFrequency(\"hello\", af) }.isSuccess // WordFrequencies does not support af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-wright",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WordFrequencies.wordFrequencyOrNull(\"hello\", af) == null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "WordFrequencies.getAllWordFrequenciesOrNull(sv)?.entries?.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-nomination",
   "metadata": {},
   "source": [
    "### Stemmer\n",
    "\n",
    "The stemmer uses [Snowballstem](http://snowballstem.org/) which is a small dependency with a wrapper.  \n",
    "If the stemmer is not supported by the called `LanguageSupport` it'll fall-back to the classic `PorterStemmer`.\n",
    "\n",
    "\n",
    "There exists two ways to call the stemmer currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.londogard.nlp.stemmer.Stemmer\n",
    "\n",
    "val stemmer = Stemmer(sv)\n",
    "stemmer.stem(\"katten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemmer.stem(\"katten\", sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-anger",
   "metadata": {},
   "source": [
    "### Trie\n",
    "\n",
    ":warning: Work In Progress :warning:\n",
    "\n",
    "Does work with a `vocab: Map<String, Int>`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "pygments_lexer": "kotlin",
   "version": "1.5.0-dev-1206"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
